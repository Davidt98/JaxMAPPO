"LR": 3.5e-4 # used 3.5 in all runs! except for the run where 2.5 is written see slides
# "LR": 3.5e-4 # siehe presentation, where LR: 3.5 wasnt specified 2.5 waas prob used
"NUM_ENVS": 48 # final presentation param
"NUM_STEPS": 256 # final presentation param
# "LR": 3.5e-4
# "NUM_ENVS": 128 # final presentation for code not using r2i impl
# "NUM_STEPS": 512 # final presentation for code not using r2i impl
# "TOTAL_TIMESTEPS": 7.5e+6
# "TOTAL_TIMESTEPS": 1.0e+7 # 6.5e6 for final presentation run.. nochmal nachrechnen if doubts..
"TOTAL_TIMESTEPS": 1.0e+7
"UPDATE_EPOCHS": 4
"NUM_MINIBATCHES": 4
"GAMMA": 0.99
"GAE_LAMBDA": 0.95
"CLIP_EPS": 0.2
"SCALE_CLIP_EPS": False
"ENT_COEF": 0.01
"VF_COEF": 0.5
"MAX_GRAD_NORM": 0.5
"ACTIVATION": "tanh"
"ENV_NAME": "overcooked"
# "ENV_KWARGS": 
#   "layout" : "cramped_room"
# "LAYOUTS": ["cramped_room", "asymm_advantages", "coord_ring", "forced_coord", "counter_circuit"]
"LAYOUTS": ["asymm_advantages"]
"ANNEAL_LR": True
"SEED": 0
"NUM_SEEDS": 3

# WandB Params
"WANDB_MODE": "online"
"ENTITY": "thichqwerty"
"PROJECT": "r2i_mappo_overcooked"


# Config for R2I part
"rssm": {
  deter: 4096, 
  units: 1024, 
  hidden: 128, 
  stoch: 32, 
  classes: 32, 
  act: silu, 
  norm: layer, 
  initial: learned, 
  unimix: 0.01, 
  unroll: True, 
  action_clip: 1.0, 
  winit: normal, 
  fan: avg, 
  nonrecurrent_enc: False
}

"ssm": 
  n_layers: 2 # reduced from 4 bc of gpu memory  
  prenorm: False
  mlp: True
  glu: True
  dropout: 0.0
  parallel: True
  conv: False
  use_norm: True

"ssm_cell":
  reset_mode: init
  n_blocks: 8
  C_init: trunc_standard_normal
  conj_sym: False
  discretization: bilinear
  clip_eigs: False
  dt_min: 0.001
  dt_max: 0.1

"ssm_type": mimo
